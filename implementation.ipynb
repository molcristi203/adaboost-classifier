{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function defines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyConvolution(src : cv2.Mat, kernel, dtype):\n",
    "    h, w  = src.shape[:2]\n",
    "\n",
    "    kH, kW = kernel.shape[:2]\n",
    "    padH, padW = kH // 2, kW // 2\n",
    "\n",
    "    dst = src.copy()\n",
    "\n",
    "    for i in range(padH, h - padH):\n",
    "        for j in range(padW, w - padW):\n",
    "            value = 0.0\n",
    "            for u in range(kH):\n",
    "                for v in range(kW):\n",
    "                    value += kernel[int(u)][int(v)] * src[int(i + u - kH)][int(j + v - kW)]\n",
    "            dst[i][j] = value\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG(image, blockSize, cellSize, nbins):\n",
    "    h, w  = image.shape[:2]\n",
    "\n",
    "    image = np.float32(image)\n",
    "    gx = applyConvolution(image, np.float32([[-1, 0, 1]]), np.float32)\n",
    "    gy = applyConvolution(image, np.float32([[-1], [0], [1]]), np.float32)\n",
    "\n",
    "    magnitude = np.sqrt(gx**2 + gy**2)\n",
    "    angle = np.arctan2(gy, gx) * (180 / np.pi) % 180\n",
    "\n",
    "    cW, cH = cellSize\n",
    "\n",
    "    hist = np.zeros((h // cH, w // cW, nbins), np.float32)\n",
    "\n",
    "    binLength = 180.0 / float(nbins)\n",
    "\n",
    "    for i in range(0, h, cH):\n",
    "        for j in range(0, w, cW):\n",
    "            for u in range(i, i + cH):\n",
    "                for v in range(j, j + cW):\n",
    "                    mH = angle[int(u)][int(v)] / binLength\n",
    "                    lH = float(math.floor(mH))\n",
    "                    rH = float(math.floor(mH + 1) % nbins)\n",
    "                    cL = 1.0 - (mH - lH)\n",
    "                    cR = 1.0 - abs(rH - mH)\n",
    "                    hist[int(i / cH)][int(j / cW)][int(lH)] += cL * magnitude[u][v]\n",
    "                    hist[int(i / cH)][int(j / cW)][int(rH)] += cR * magnitude[u][v]\n",
    "\n",
    "    bW, bH = blockSize\n",
    "\n",
    "    normHist = []\n",
    "\n",
    "    for i in range(0, h - cH, cH):\n",
    "        for j in range(0, w - cW, cW):\n",
    "            norm = np.array([], dtype=np.float32)\n",
    "            for u in range(i, i + bH, cH):\n",
    "                for v in range(j, j + bW, cW):\n",
    "                    norm = np.concatenate([norm, hist[int(i / cH)][int(j / cW)]])\n",
    "            norm = norm / (bH * bW)\n",
    "            normHist.append(norm)\n",
    "\n",
    "    normHist = np.float32(normHist)\n",
    "\n",
    "    return (hist.ravel(), normHist.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_SIZE = (8, 8)\n",
    "BLOCK_SIZE = (16, 16)\n",
    "NBINS = 9\n",
    "MAX_T = 300\n",
    "MAX_TRAIN = 40\n",
    "MAX_TEST = 14\n",
    "CLASSES_LIST = [\"A\", \"B\"]\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakLearner:\n",
    "  def __init__(self, feature, threshold, class_label, error):\n",
    "    self.feature = feature\n",
    "    self.threshold = threshold\n",
    "    self.class_label = class_label\n",
    "    self.error = error\n",
    "\n",
    "  def classify(self, X):\n",
    "    return self.class_label if X[self.feature] < self.threshold else -self.class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrongClassifier:\n",
    "  def __init__(self):\n",
    "    self.weak_learners = np.array([])\n",
    "    self.alphas = np.array([])\n",
    "\n",
    "  def classify(self, X):\n",
    "    sum = np.sum(self.alphas * [weak.classify(X) for weak in self.weak_learners])\n",
    "    return 1 if sum >= 0 else -1\n",
    "\n",
    "  def add_weak_learner(self, weak_learner, alpha):\n",
    "    self.weak_learners = np.append(self.weak_learners, weak_learner)\n",
    "    self.alphas = np.append(self.alphas, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weak_learner(X, y, weight):\n",
    "  best_weak_learner = None\n",
    "  best_error = float('inf')\n",
    "\n",
    "  h, w  = X.shape[:2]\n",
    "\n",
    "  for j in range(w):\n",
    "    sorted_values = np.sort(X[:, j])\n",
    "    thresholds = (sorted_values[:-1] + sorted_values[1:]) / 2\n",
    "    for threshold in thresholds:\n",
    "      for class_label in [-1, 1]:\n",
    "        error = 0\n",
    "        for i in range(h):\n",
    "          zi = 0\n",
    "          if X[i][j] < threshold:\n",
    "            zi = class_label\n",
    "          else:\n",
    "            zi = -class_label\n",
    "          if zi * y[i] < 0:\n",
    "            error += weight[i]\n",
    "\n",
    "        if error < best_error:\n",
    "          best_error = error\n",
    "          best_weak_learner = WeakLearner(j, threshold, class_label, error)\n",
    "\n",
    "  return best_weak_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_strong_classifier(X, y):\n",
    "  h, w  = X.shape[:2]\n",
    "  weight = np.ones(h) / h\n",
    "  classifier = StrongClassifier()\n",
    "\n",
    "  for t in range(MAX_T):\n",
    "    weak_learner = find_weak_learner(X, y, weight)\n",
    "    alpha = 0.5 * math.log((1 - weak_learner.error + EPSILON) / (weak_learner.error + EPSILON))\n",
    "    predictions = np.array([weak_learner.classify(X[i]) for i in range(h)])\n",
    "    weight *= np.exp(-alpha * y * predictions)\n",
    "    s = np.sum(weight)\n",
    "    weight /= s\n",
    "    classifier.add_weak_learner(weak_learner, alpha)\n",
    "\n",
    "  return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "  resized = cv2.resize(blur, (128, 128))\n",
    "  return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process image testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread(os.path.join(\"dataset\", \"test\", \"B\", \"hand1_b_bot_seg_5_cropped.jpeg\"))\n",
    "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "processed_image = process_image(test_image)\n",
    "plt.imshow(processed_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir, limit):\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  for cls in CLASSES_LIST:\n",
    "    category = os.path.join(dir, cls)\n",
    "    X_category = []\n",
    "    y_category = []\n",
    "\n",
    "    for img in os.listdir(category):\n",
    "      image = cv2.imread(os.path.join(category, img))\n",
    "      processed_image = process_image(image)\n",
    "      _, features = HOG(processed_image, BLOCK_SIZE, CELL_SIZE, NBINS)\n",
    "      X_category.append(features)\n",
    "      if cls == CLASSES_LIST[0]:\n",
    "        y_category.append(1)\n",
    "      else:\n",
    "        y_category.append(-1)\n",
    "\n",
    "    data_category = list(zip(X_category, y_category))\n",
    "    random.shuffle(data_category)\n",
    "    X_shuffled, y_shuffled = zip(*data_category)\n",
    "    X += X_shuffled[:limit]\n",
    "    y += y_shuffled[:limit]\n",
    "\n",
    "  X = np.array(X)\n",
    "  y = np.array(y)\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_pred, y_real):\n",
    "  h = y_pred.shape[0]\n",
    "  confusion_matrix = np.zeros((2, 2))\n",
    "\n",
    "  for i in range(h):\n",
    "    if y_real[i] == 1:\n",
    "      if y_pred[i] == 1:\n",
    "        confusion_matrix[0][0] += 1\n",
    "      else:\n",
    "        confusion_matrix[0][1] += 1\n",
    "    else:\n",
    "      if y_pred[i] == 1:\n",
    "        confusion_matrix[1][0] += 1\n",
    "      else:\n",
    "        confusion_matrix[1][1] += 1\n",
    "\n",
    "  return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(classifier, X, y):\n",
    "  y_pred = np.array([classifier.classify(X[i]) for i in range(X.shape[0])])\n",
    "  confusion_matrix = compute_confusion_matrix(y_pred, y)\n",
    "\n",
    "  accuracy = (confusion_matrix[0][0] + confusion_matrix[1][1]) / np.sum(confusion_matrix)\n",
    "  precision = confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[0][1])\n",
    "  recall = confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[1][0])\n",
    "  f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "  return confusion_matrix, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adaboost(classifier, X, y):\n",
    "  y_pred = classifier.predict(X)\n",
    "  confusion_matrix = compute_confusion_matrix(y_pred, y)\n",
    "\n",
    "  accuracy = (confusion_matrix[0][0] + confusion_matrix[1][1]) / np.sum(confusion_matrix)\n",
    "  precision = confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[0][1])\n",
    "  recall = confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[1][0])\n",
    "  f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "  return confusion_matrix, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(os.path.join(\"dataset\", \"train\"), MAX_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = find_strong_classifier(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(classifier, 'adaboost_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_classifier = joblib.load(\"adaboost_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model by predicting two images from different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imageA = cv2.imread(os.path.join(\"dataset\", \"test\", \"A\", \"hand1_a_bot_seg_5_cropped.jpeg\"))\n",
    "processed_imageA = process_image(test_imageA)\n",
    "\n",
    "plt.imshow(processed_imageA, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "_, featuresA = HOG(processed_imageA, BLOCK_SIZE, CELL_SIZE, NBINS)\n",
    "print(loaded_classifier.classify(featuresA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imageB = cv2.imread(os.path.join(\"dataset\", \"test\", \"B\", \"hand1_b_bot_seg_5_cropped.jpeg\"))\n",
    "processed_imageB = process_image(test_imageB)\n",
    "\n",
    "plt.imshow(processed_imageB, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "_, featuresB = HOG(processed_imageB, BLOCK_SIZE, CELL_SIZE, NBINS)\n",
    "print(loaded_classifier.classify(featuresB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest, ytest = load_data(os.path.join(\"dataset\", \"test\"), MAX_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model by make it predict all the images from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, accuracy, precision, recall, f1 = test_classifier(loaded_classifier, Xtest, ytest)\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g', xticklabels=['A', 'B'], yticklabels=['A', 'B'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the sklearn AdaBoost model and testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost = AdaBoostClassifier(estimator=base_estimator, n_estimators=MAX_T, random_state=42)\n",
    "adaboost.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(adaboost, 'adaboost_sklearn_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_sklearn_classifier = joblib.load(\"adaboost_sklearn_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imageA = cv2.imread(os.path.join(\"dataset\", \"test\", \"A\", \"hand1_a_bot_seg_5_cropped.jpeg\"))\n",
    "processed_imageA = process_image(test_imageA)\n",
    "_, featuresA = HOG(processed_imageA, BLOCK_SIZE, CELL_SIZE, NBINS)\n",
    "featuresA_reshaped = featuresA.reshape(1, -1)\n",
    "print(loaded_sklearn_classifier.predict(featuresA_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imageB = cv2.imread(os.path.join(\"dataset\", \"test\", \"B\", \"hand1_b_bot_seg_5_cropped.jpeg\"))\n",
    "processed_imageB = process_image(test_imageB)\n",
    "_, featuresB = HOG(processed_imageB, BLOCK_SIZE, CELL_SIZE, NBINS)\n",
    "featuresB_reshaped = featuresB.reshape(1, -1)\n",
    "print(loaded_sklearn_classifier.predict(featuresB_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, accuracy, precision, recall, f1 = test_adaboost(loaded_sklearn_classifier, Xtest, ytest)\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g', xticklabels=['A', 'B'], yticklabels=['A', 'B'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
